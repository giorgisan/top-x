name: Daily fetch tweets (snscrape)

on:
  workflow_dispatch:
  schedule:
    - cron: '20 5 * * *'   # 05:20 UTC

jobs:
  fetch:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # ⬇️ ključni popravek: Python 3.11 + pin snscrape
      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install snscrape
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir "snscrape==0.7.0"
          snscrape --version

      - name: Install Node deps
        run: npm ci || npm i

      - name: Scrape yesterday (SLO)
        run: |
          set -e
          YESTERDAY=$(date -u -d "yesterday" +%F)
          TODAY=$(date -u +%F)
          echo "Scraping from $YESTERDAY to $TODAY (UTC)"

          rm -f scraped.jsonl

          snscrape --jsonl twitter-search "lang:sl since:$YESTERDAY until:$TODAY" >> scraped.jsonl || true
          snscrape --jsonl twitter-search "lang:sl (Slovenija OR Ljubljana OR Maribor OR Celje OR Koper OR Kranj OR Gorenjska OR Primorska OR Štajerska OR Dolenjska OR Prekmurje OR slovenski OR slovenska OR slovenskem) since:$YESTERDAY until:$TODAY" >> scraped.jsonl || true

          ACCOUNTS=(STA_novice RTV_Slovenija 24ur_com vecer Delo Dnevnik_si SiolNEWS FinanceSI vladaRS DrzavniZbor Arso_Vreme nzs_si nkmaribor nkolimpija OKS_olympicteam TeamSlovenia)
          for U in "${ACCOUNTS[@]}"; do
            snscrape --jsonl twitter-search "from:$U since:$YESTERDAY until:$TODAY" >> scraped.jsonl || true
          done

          echo "Lines in scraped.jsonl:"
          wc -l scraped.jsonl || true

      - name: Import into Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        run: node scripts/import_from_jsonl.mjs scraped.jsonl
