name: Daily fetch tweets (snscrape)

on:
  workflow_dispatch:
  schedule:
    - cron: '20 5 * * *'   # 05:20 UTC

jobs:
  fetch:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # Python 3.11 (snscrape je stabilen na 3.10/3.11)
      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # Zadnja snscrape iz GitHub-a (pogosto vsebuje fix-e)
      - name: Install snscrape
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir "git+https://github.com/JustAnotherArchivist/snscrape.git"
          snscrape --version

      - name: Install Node deps
        run: npm ci || npm i

      - name: Scrape yesterday (SLO)
        shell: bash
        run: |
          set -euo pipefail
          YESTERDAY=$(date -u -d "yesterday" +%F)
          TODAY=$(date -u +%F)
          echo "Scraping from $YESTERDAY to $TODAY (UTC)"

          rm -f scraped.jsonl
          touch scraped.jsonl

          # 1) jezik
          snscrape --jsonl twitter-search "lang:sl since:$YESTERDAY until:$TODAY" >> scraped.jsonl || true

          # 2) dodatni slovenski kontekst
          snscrape --jsonl twitter-search "lang:sl (Slovenija OR Ljubljana OR Maribor OR Celje OR Koper OR Kranj OR Gorenjska OR Primorska OR Štajerska OR Dolenjska OR Prekmurje OR slovenski OR slovenska OR slovenskem) since:$YESTERDAY until:$TODAY" >> scraped.jsonl || true

          # 3) večji SLO računi
          ACCOUNTS=(STA_novice RTV_Slovenija 24ur_com vecer Delo Dnevnik_si SiolNEWS FinanceSI vladaRS DrzavniZbor Arso_Vreme nzs_si nkmaribor nkolimpija OKS_olympicteam TeamSlovenia)
          for U in "${ACCOUNTS[@]}"; do
            snscrape --jsonl twitter-search "from:$U since:$YESTERDAY until:$TODAY" >> scraped.jsonl || true
          done

          echo "----- SCRAPE SUMMARY -----"
          if [ -s scraped.jsonl ]; then
            LINES=$(wc -l < scraped.jsonl)
            echo "scraped.jsonl lines: $LINES"
            head -n 3 scraped.jsonl || true
          else
            echo "scraped.jsonl is EMPTY"
          fi

      # Vedno priložimo artefakt, da lahko preveriš surove zadetke
      - name: Upload scraped.jsonl artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraped-jsonl
          path: scraped.jsonl
          if-no-files-found: warn
          retention-days: 3

      # Uvoz izvedemo samo, če datoteka ni prazna
      - name: Import into Supabase
        if: ${{ hashFiles('scraped.jsonl') != '' && steps.check_empty.outputs.empty != 'true' }}
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        run: node scripts/import_from_jsonl.mjs scraped.jsonl
